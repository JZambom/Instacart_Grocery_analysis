{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e94aeccb-f206-46ab-b294-6293722c3a12",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0be93c0-dc8e-468e-818d-189c97e24134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id First Name    Surnam  Gender       STATE  Age date_joined  \\\n",
      "0    26711    Deborah  Esquivel  Female    Missouri   48    1/1/2017   \n",
      "1    33890   Patricia      Hart  Female  New Mexico   36    1/1/2017   \n",
      "2    65803    Kenneth    Farley    Male       Idaho   35    1/1/2017   \n",
      "3   125935   Michelle     Hicks  Female        Iowa   40    1/1/2017   \n",
      "4   130797        Ann   Gilmore  Female    Maryland   26    1/1/2017   \n",
      "\n",
      "   n_dependants fam_status  income  \n",
      "0             3    married  165665  \n",
      "1             0     single   59285  \n",
      "2             2    married   99568  \n",
      "3             0     single   42049  \n",
      "4             1    married   40374  \n"
     ]
    }
   ],
   "source": [
    "# Step 3: Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define the file path for the customer data\n",
    "customer_data_path = r'C:\\Users\\Jose Zambom\\OneDrive - Exel Industries\\Data Analysis\\Data Analytics Immersion\\Python Fundamentals for Data Analyst\\csv file\\4.9_Intro to data visualization with Python\\customers.csv'\n",
    "\n",
    "# Load the customer data into a pandas DataFrame\n",
    "df_customers = pd.read_csv(customer_data_path)\n",
    "\n",
    "#Check the first few rows of the customer data\n",
    "print(df_customers.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75d8f260-bfff-4e94-9028-13a3da0aa5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id first_name   surname  gender       state  age date_joined  \\\n",
      "0    26711    Deborah  Esquivel  Female    Missouri   48    1/1/2017   \n",
      "1    33890   Patricia      Hart  Female  New Mexico   36    1/1/2017   \n",
      "2    65803    Kenneth    Farley    Male       Idaho   35    1/1/2017   \n",
      "3   125935   Michelle     Hicks  Female        Iowa   40    1/1/2017   \n",
      "4   130797        Ann   Gilmore  Female    Maryland   26    1/1/2017   \n",
      "\n",
      "   num_dependants family_status  income  \n",
      "0               3       married  165665  \n",
      "1               0        single   59285  \n",
      "2               2       married   99568  \n",
      "3               0        single   42049  \n",
      "4               1       married   40374  \n"
     ]
    }
   ],
   "source": [
    "# Step 4: Renaming columns to follow consistent naming conventions\n",
    "\n",
    "df_customers.rename(columns={\n",
    "    'First Name' : 'first_name',\n",
    "    'Surnam' : 'surname',\n",
    "    'Gender' : 'gender',\n",
    "    'STATE' : 'state',\n",
    "    'Age' : 'age',\n",
    "    'data_joined' : 'date_joined',\n",
    "    'n_dependants' : 'num_dependants',\n",
    "    'fam_status' : 'family_status',\n",
    "    'income' : 'income'\n",
    "}, inplace = True)\n",
    "\n",
    "print(df_customers.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1048f7d-cfcb-41ca-8f13-401d88ec9803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values in each column:\n",
      " user_id               0\n",
      "first_name        11259\n",
      "surname               0\n",
      "gender                0\n",
      "state                 0\n",
      "age                   0\n",
      "date_joined           0\n",
      "num_dependants        0\n",
      "family_status         0\n",
      "income                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checkin for Missing Values\n",
    "missing_values = df_customers.isnull().sum()\n",
    "print(\"Missing Values in each column:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1d2e6e0-acab-45ad-9acd-e148d90cc8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'gender', 'state', 'age', 'date_joined', 'num_dependants',\n",
      "       'family_status', 'income'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Drop the first_name column since it has a lot of missing values and may not be needed\n",
    "df_customers.drop(columns=['first_name', 'surname'], inplace = True)\n",
    "\n",
    "print(df_customers.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "616f82d4-de55-42d3-93f8-8fed867cc211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows found:\n",
      " Empty DataFrame\n",
      "Columns: [user_id, gender, state, age, date_joined, num_dependants, family_status, income]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# checking for duplicates\n",
    "duplicate_rows = df_customers[df_customers.duplicated()]\n",
    "# Display duplicate rows\n",
    "print(\"Duplicate rows found:\\n\", duplicate_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae18459a-1c02-4dbd-8f08-045b56ae745f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No mixed types in column 'user_id'\n",
      "No mixed types in column 'gender'\n",
      "No mixed types in column 'state'\n",
      "No mixed types in column 'age'\n",
      "No mixed types in column 'date_joined'\n",
      "No mixed types in column 'num_dependants'\n",
      "No mixed types in column 'family_status'\n",
      "No mixed types in column 'income'\n"
     ]
    }
   ],
   "source": [
    "# Check for mixed-type data in the DataFrame\n",
    "for col in df_customers.columns:\n",
    "    # Check if the column contains more than one unique data type\n",
    "    if df_customers[col].apply(type).nunique() > 1:\n",
    "        print(f\"Mixed types found in column '{col}'\")\n",
    "    else:\n",
    "        print(f\"No mixed types in column '{col}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8503d819-07e5-459b-b4e1-22a259e71187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id  user_id eval_set  order_number  orders_day_of_week  \\\n",
      "0         2   202279    prior             3                   5   \n",
      "1         2   202279    prior             3                   5   \n",
      "2         2   202279    prior             3                   5   \n",
      "3         2   202279    prior             3                   5   \n",
      "4         2   202279    prior             3                   5   \n",
      "\n",
      "   order_hour_of_day  days_since_prior_order  product_id  add_to_cart_order  \\\n",
      "0                  9                     8.0     33120.0                1.0   \n",
      "1                  9                     8.0     28985.0                2.0   \n",
      "2                  9                     8.0      9327.0                3.0   \n",
      "3                  9                     8.0     45918.0                4.0   \n",
      "4                  9                     8.0     30035.0                5.0   \n",
      "\n",
      "   reordered  ...        price_range    price_range_loc  busiest_days  \\\n",
      "0        1.0  ...  Mid-range product  Mid-range product  Regular days   \n",
      "1        1.0  ...  Mid-range product  Mid-range product  Regular days   \n",
      "2        0.0  ...  Low-range product  Low-range product  Regular days   \n",
      "3        1.0  ...  Mid-range product  Mid-range product  Regular days   \n",
      "4        0.0  ...  Mid-range product  Mid-range product  Regular days   \n",
      "\n",
      "   busiest_period_of_day max_order  loyalty_flag mean_price spending_flag  \\\n",
      "0            Most orders         8  New Customer   8.590476   Low spender   \n",
      "1            Most orders         8  New Customer   8.590476   Low spender   \n",
      "2            Most orders         8  New Customer   8.590476   Low spender   \n",
      "3            Most orders         8  New Customer   8.590476   Low spender   \n",
      "4            Most orders         8  New Customer   8.590476   Low spender   \n",
      "\n",
      "  median_days_since_prior_order   order_frequency_flag  \n",
      "0                          30.0  Non-frequent customer  \n",
      "1                          30.0  Non-frequent customer  \n",
      "2                          30.0  Non-frequent customer  \n",
      "3                          30.0  Non-frequent customer  \n",
      "4                          30.0  Non-frequent customer  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the file path for the orders_products_with_flags.pkl file\n",
    "orders_products_path = r'C:\\Users\\Jose Zambom\\OneDrive - Exel Industries\\Data Analysis\\Data Analytics Immersion\\Python Fundamentals for Data Analyst\\csv file\\Prepared Data\\orders_products_with_flags.pkl'\n",
    "\n",
    "# Load the pickle file into a DataFrame\n",
    "orders_products_with_flags = pd.read_pickle(orders_products_path)\n",
    "\n",
    "# Check the first few rows to confirm the data has been loaded correctly\n",
    "print(orders_products_with_flags.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7618b90d-5118-451d-b20e-42f6801a5d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  gender       state  age date_joined  num_dependants family_status  \\\n",
      "0    26711  Female    Missouri   48    1/1/2017               3       married   \n",
      "1    33890  Female  New Mexico   36    1/1/2017               0        single   \n",
      "2    65803    Male       Idaho   35    1/1/2017               2       married   \n",
      "3   125935  Female        Iowa   40    1/1/2017               0        single   \n",
      "4   130797  Female    Maryland   26    1/1/2017               1       married   \n",
      "\n",
      "   income  \n",
      "0  165665  \n",
      "1   59285  \n",
      "2   99568  \n",
      "3   42049  \n",
      "4   40374  \n"
     ]
    }
   ],
   "source": [
    "print(df_customers.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6994415b-f396-4fa4-902f-313ed9169b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id  user_id eval_set  order_number  orders_day_of_week  \\\n",
      "0         2   202279    prior             3                   5   \n",
      "1         2   202279    prior             3                   5   \n",
      "2         2   202279    prior             3                   5   \n",
      "3         2   202279    prior             3                   5   \n",
      "4         2   202279    prior             3                   5   \n",
      "\n",
      "   order_hour_of_day  days_since_prior_order  product_id  add_to_cart_order  \\\n",
      "0                  9                     8.0     33120.0                1.0   \n",
      "1                  9                     8.0     28985.0                2.0   \n",
      "2                  9                     8.0      9327.0                3.0   \n",
      "3                  9                     8.0     45918.0                4.0   \n",
      "4                  9                     8.0     30035.0                5.0   \n",
      "\n",
      "   reordered  ... spending_flag  median_days_since_prior_order  \\\n",
      "0        1.0  ...   Low spender                           30.0   \n",
      "1        1.0  ...   Low spender                           30.0   \n",
      "2        0.0  ...   Low spender                           30.0   \n",
      "3        1.0  ...   Low spender                           30.0   \n",
      "4        0.0  ...   Low spender                           30.0   \n",
      "\n",
      "    order_frequency_flag  gender  state age date_joined num_dependants  \\\n",
      "0  Non-frequent customer    Male  Idaho  57    2/6/2020              3   \n",
      "1  Non-frequent customer    Male  Idaho  57    2/6/2020              3   \n",
      "2  Non-frequent customer    Male  Idaho  57    2/6/2020              3   \n",
      "3  Non-frequent customer    Male  Idaho  57    2/6/2020              3   \n",
      "4  Non-frequent customer    Male  Idaho  57    2/6/2020              3   \n",
      "\n",
      "  family_status  income  \n",
      "0       married   98119  \n",
      "1       married   98119  \n",
      "2       married   98119  \n",
      "3       married   98119  \n",
      "4       married   98119  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 6\n",
    "# Ensure 'user_id' is the same data type in both DataFrames\n",
    "df_customers['user_id'] = df_customers['user_id'].astype(int)\n",
    "orders_products_with_flags['user_id'] = orders_products_with_flags['user_id'].astype(int)\n",
    "\n",
    "# Merge the customer data with the orders_products_with_flags data on 'user_id'\n",
    "combined_data = pd.merge(orders_products_with_flags, df_customers, on='user_id', how='inner')\n",
    "\n",
    "# Check the first few rows of the combined DataFrame\n",
    "print(combined_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "607ac592-83f4-4a1b-9be4-6649dd9aa114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully exported to C:\\Users\\Jose Zambom\\OneDrive - Exel Industries\\Data Analysis\\Data Analytics Immersion\\Python Fundamentals for Data Analyst\\csv file\\Prepared Data\\combined_data.pkl\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Export dataframe as pickle file\n",
    "# Define the path to save the combined pickle file\n",
    "combined_data_path = r'C:\\Users\\Jose Zambom\\OneDrive - Exel Industries\\Data Analysis\\Data Analytics Immersion\\Python Fundamentals for Data Analyst\\csv file\\Prepared Data\\combined_data.pkl'\n",
    "\n",
    "# Export the combined DataFrame as a pickle file\n",
    "combined_data.to_pickle(combined_data_path)\n",
    "\n",
    "# Confirm the export\n",
    "print(f\"Data successfully exported to {combined_data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d3ae0f-e729-4af6-b8ad-9e42ce4fd6f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
